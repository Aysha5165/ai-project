{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDKY0V-uKecZ",
        "outputId": "c251e23f-e864-43a8-d0aa-54271189c3c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     Smartphone     Brand           Model  \\\n",
            "0            Realme C55 8/256GB Sunshower Libre    Realme             C55   \n",
            "1      Samsung Galaxy M23 5G 4/128GB Azul Libre   Samsung      Galaxy M23   \n",
            "2  Motorola Moto G13 4/128GB Azul Lavanda Libre  Motorola        Moto G13   \n",
            "3      Xiaomi Redmi Note 11S 6/128GB Gris Libre    Xiaomi  Redmi Note 11S   \n",
            "4       Nothing Phone (2) 12/512GB Blanco Libre   Nothing       Phone (2)   \n",
            "\n",
            "    RAM  Storage   Color Free  Final Price  \n",
            "0   8.0    256.0  Yellow  Yes       231.60  \n",
            "1   4.0    128.0    Blue  Yes       279.00  \n",
            "2   4.0    128.0    Blue  Yes       179.01  \n",
            "3   6.0    128.0    Gray  Yes       279.99  \n",
            "4  12.0    512.0   White  Yes       799.00  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1816 entries, 0 to 1815\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Smartphone   1816 non-null   object \n",
            " 1   Brand        1816 non-null   object \n",
            " 2   Model        1816 non-null   object \n",
            " 3   RAM          1333 non-null   float64\n",
            " 4   Storage      1791 non-null   float64\n",
            " 5   Color        1816 non-null   object \n",
            " 6   Free         1816 non-null   object \n",
            " 7   Final Price  1816 non-null   float64\n",
            "dtypes: float64(3), object(5)\n",
            "memory usage: 113.6+ KB\n",
            "None\n",
            "              RAM      Storage  Final Price\n",
            "count  1333.00000  1791.000000  1816.000000\n",
            "mean      5.96099   162.652150   492.175573\n",
            "std       2.66807   139.411605   398.606183\n",
            "min       1.00000     2.000000    60.460000\n",
            "25%       4.00000    64.000000   200.990000\n",
            "50%       6.00000   128.000000   349.990000\n",
            "75%       8.00000   256.000000   652.717500\n",
            "max      12.00000  1000.000000  2271.280000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'smartphones.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EXrJ6bfLf6F",
        "outputId": "ec53daed-bbb4-4cf8-a613-9d15fedfd342"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Smartphone     0\n",
              "Brand          0\n",
              "Model          0\n",
              "RAM            0\n",
              "Storage        0\n",
              "Color          0\n",
              "Free           0\n",
              "Final Price    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Fill missing values with median\n",
        "df['RAM'].fillna(df['RAM'].median(), inplace=True)\n",
        "df['Storage'].fillna(df['Storage'].median(), inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for column in ['Brand', 'Model', 'Color', 'Free']:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Split data into features and target\n",
        "X = df.drop(['Smartphone', 'Final Price'], axis=1)\n",
        "y = df['Final Price']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize/scale the numerical features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "vLXpDWhUKimJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Dictionary to store the evaluation metrics for each model\n",
        "results = {}\n",
        "\n",
        "# Function to evaluate a model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return {\n",
        "        'RMSE': mean_squared_error(y_test, y_pred, squared=False),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "\n",
        "# Decision Tree Regressor\n",
        "decision_tree = DecisionTreeRegressor()\n",
        "results['Decision Tree'] = evaluate_model(decision_tree, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Random Forest Regressor\n",
        "random_forest = RandomForestRegressor()\n",
        "results['Random Forest'] = evaluate_model(random_forest, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Support Vector Machine (SVR)\n",
        "svr = SVR()\n",
        "results['SVR'] = evaluate_model(svr, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# k-Nearest Neighbors (k-NN)\n",
        "knn = KNeighborsRegressor()\n",
        "results['k-NN'] = evaluate_model(knn, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Gradient Boosting Regressor\n",
        "gbr = GradientBoostingRegressor()\n",
        "results['Gradient Boosting'] = evaluate_model(gbr, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Gaussian Naive Bayes (not typically used for regression, but included for completeness)\n",
        "# Convert target variable to categorical for Naive Bayes\n",
        "y_train_nb = pd.cut(y_train, bins=5, labels=False)\n",
        "y_test_nb = pd.cut(y_test, bins=5, labels=False)\n",
        "naive_bayes = GaussianNB()\n",
        "results['Naive Bayes'] = evaluate_model(naive_bayes, X_train, X_test, y_train_nb, y_test_nb)\n",
        "\n",
        "# Print the results\n",
        "for model, metrics in results.items():\n",
        "    print(f\"Model: {model}\")\n",
        "    for metric, score in metrics.items():\n",
        "        print(f\"{metric}: {score:.4f}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Determine the best model based on a chosen metric (e.g., RMSE)\n",
        "best_model = min(results, key=lambda x: results[x]['RMSE'])\n",
        "print(f\"The best model is: {best_model}\")\n"
      ],
      "metadata": {
        "id": "g1kF-UovKkYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d9229c-ed3e-48d1-db38-2ca32471b290"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Decision Tree\n",
            "RMSE: 223.9503\n",
            "MAE: 138.8084\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "RMSE: 201.1033\n",
            "MAE: 124.4030\n",
            "\n",
            "\n",
            "Model: SVR\n",
            "RMSE: 436.8912\n",
            "MAE: 272.3355\n",
            "\n",
            "\n",
            "Model: k-NN\n",
            "RMSE: 262.8670\n",
            "MAE: 173.7760\n",
            "\n",
            "\n",
            "Model: Gradient Boosting\n",
            "RMSE: 192.2926\n",
            "MAE: 125.0495\n",
            "\n",
            "\n",
            "Model: Naive Bayes\n",
            "RMSE: 2.4596\n",
            "MAE: 1.8187\n",
            "\n",
            "\n",
            "The best model is: Naive Bayes\n"
          ]
        }
      ]
    }
  ]
}